[{"path":"https://sevvandi.github.io/lookout/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Sevvandi Kandanaarachchi. Author, maintainer. Rob Hyndman. Author. Chris Fraley. Contributor.","code":""},{"path":"https://sevvandi.github.io/lookout/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Kandanaarachchi S, Hyndman R (2025). lookout: Leave One Kernel Density Estimates Outlier Detection. R package version 0.1.5, https://sevvandi.github.io/lookout/.","code":"@Manual{,   title = {lookout: Leave One Out Kernel Density Estimates for Outlier Detection},   author = {Sevvandi Kandanaarachchi and Rob Hyndman},   year = {2025},   note = {R package version 0.1.5},   url = {https://sevvandi.github.io/lookout/}, }"},{"path":"https://sevvandi.github.io/lookout/index.html","id":"lookout-","dir":"","previous_headings":"","what":"Leave One Out Kernel Density Estimates for Outlier Detection","title":"Leave One Out Kernel Density Estimates for Outlier Detection","text":"lookout identifies outliers data using leave-one-kernel density estimates extreme value theory. bandwidth kernel density estimates computed using persistent homology, technique topological data analysis. Using peak--threshold method, Generalized Pareto Distribution fitted log leave-one-kde values identify outliers. See Kandanaarachchi Hyndman (2021) underlying methodology.","code":""},{"path":"https://sevvandi.github.io/lookout/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Leave One Out Kernel Density Estimates for Outlier Detection","text":"can install released version lookout CRAN : development version GitHub :","code":"#install.packages(\"lookout\") # install.packages(\"devtools\") devtools::install_github(\"sevvandi/lookout\")"},{"path":"https://sevvandi.github.io/lookout/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Leave One Out Kernel Density Estimates for Outlier Detection","text":"Next look outlier persistence. outlier persistence plot shows outliers persist range bandwidth values different levels significance. strength inversely proportional level significance. level significance 0.01, strength 10 0.1, strength 1.","code":"library(lookout) lo <- lookout(faithful) lo #> Leave-out-out KDE outliers using lookout algorithm #>  #> Call: lookout(X = faithful) #>  #>   Outliers Probability #> 1        6 0.005553188 #> 2       24 0.006423949 #> 3       46 0.007934127 #> 4      149 0.008300670 #> 5      158 0.007242257 #> 6      197 0.004333429 #> 7      211 0.000000000 #> 8      244 0.004956339 autoplot(lo) persistence <- persisting_outliers(faithful) autoplot(persistence)"},{"path":"https://sevvandi.github.io/lookout/reference/autoplot.lookoutliers.html","id":null,"dir":"Reference","previous_headings":"","what":"Plots outliers identified by lookout algorithm. — autoplot.lookoutliers","title":"Plots outliers identified by lookout algorithm. — autoplot.lookoutliers","text":"Scatterplot two columns data set outliers highlighted.","code":""},{"path":"https://sevvandi.github.io/lookout/reference/autoplot.lookoutliers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plots outliers identified by lookout algorithm. — autoplot.lookoutliers","text":"","code":"# S3 method for class 'lookoutliers' autoplot(object, columns = 1:2, ...)"},{"path":"https://sevvandi.github.io/lookout/reference/autoplot.lookoutliers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plots outliers identified by lookout algorithm. — autoplot.lookoutliers","text":"object output function lookout. columns columns original data plot (specified either numbers strings) ... arguments currently ignored.","code":""},{"path":"https://sevvandi.github.io/lookout/reference/autoplot.lookoutliers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plots outliers identified by lookout algorithm. — autoplot.lookoutliers","text":"ggplot object.","code":""},{"path":"https://sevvandi.github.io/lookout/reference/autoplot.lookoutliers.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plots outliers identified by lookout algorithm. — autoplot.lookoutliers","text":"","code":"X <- rbind(   data.frame(     x = rnorm(500),     y = rnorm(500)   ),   data.frame(     x = rnorm(5, mean = 10, sd = 0.2),     y = rnorm(5, mean = 10, sd = 0.2)   ) ) lo <- lookout(X) autoplot(lo)"},{"path":"https://sevvandi.github.io/lookout/reference/autoplot.persistingoutliers.html","id":null,"dir":"Reference","previous_headings":"","what":"Plots outlier persistence for a range of significance levels. — autoplot.persistingoutliers","title":"Plots outlier persistence for a range of significance levels. — autoplot.persistingoutliers","text":"function plots outlier persistence range significance levels using algorithm lookout, outlier detection method uses leave-one-kernel density estimates generalized Pareto distributions find outliers.","code":""},{"path":"https://sevvandi.github.io/lookout/reference/autoplot.persistingoutliers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plots outlier persistence for a range of significance levels. — autoplot.persistingoutliers","text":"","code":"# S3 method for class 'persistingoutliers' autoplot(object, alpha = object$alpha, ...)"},{"path":"https://sevvandi.github.io/lookout/reference/autoplot.persistingoutliers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plots outlier persistence for a range of significance levels. — autoplot.persistingoutliers","text":"object output function persisting_outliers. alpha significance levels plot. ... arguments currently ignored.","code":""},{"path":"https://sevvandi.github.io/lookout/reference/autoplot.persistingoutliers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plots outlier persistence for a range of significance levels. — autoplot.persistingoutliers","text":"ggplot object.","code":""},{"path":"https://sevvandi.github.io/lookout/reference/autoplot.persistingoutliers.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plots outlier persistence for a range of significance levels. — autoplot.persistingoutliers","text":"","code":"X <- rbind(   data.frame(     x = rnorm(500),     y = rnorm(500)   ),   data.frame(     x = rnorm(5, mean = 10, sd = 0.2),     y = rnorm(5, mean = 10, sd = 0.2)   ) ) plot(X, pch = 19)  outliers <- persisting_outliers(X, scale = FALSE) autoplot(outliers)"},{"path":"https://sevvandi.github.io/lookout/reference/find_tda_bw.html","id":null,"dir":"Reference","previous_headings":"","what":"Identifies bandwidth for outlier detection. — find_tda_bw","title":"Identifies bandwidth for outlier detection. — find_tda_bw","text":"function identifies bandwidth used kernel density estimate computation. function uses topological data analysis (TDA) find badnwidth.","code":""},{"path":"https://sevvandi.github.io/lookout/reference/find_tda_bw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identifies bandwidth for outlier detection. — find_tda_bw","text":"","code":"find_tda_bw(X, fast = TRUE, gamma = 0.95, use_differences = FALSE)"},{"path":"https://sevvandi.github.io/lookout/reference/find_tda_bw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identifies bandwidth for outlier detection. — find_tda_bw","text":"X numerical input data data.frame, matrix tibble format. fast TRUE (default), makes computation faster sub-setting data bandwidth calculation. gamma Parameter bandwidth calculation giving quantile Rips death radii use bandwidth. Default 0.97. Ignored old version; lower limit maximum Rips death radii difference used. Also ignored bw provided. use_differences TRUE, bandwidth set lower point maximum Rips death radii differences. FALSE, gamma quantile Rips death radii used. Default FALSE.","code":""},{"path":"https://sevvandi.github.io/lookout/reference/find_tda_bw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identifies bandwidth for outlier detection. — find_tda_bw","text":"bandwidth","code":""},{"path":"https://sevvandi.github.io/lookout/reference/find_tda_bw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identifies bandwidth for outlier detection. — find_tda_bw","text":"","code":"X <- rbind(   data.frame(     x = rnorm(500),     y = rnorm(500)   ),   data.frame(     x = rnorm(5, mean = 10, sd = 0.2),     y = rnorm(5, mean = 10, sd = 0.2)   ) ) find_tda_bw(X, fast = TRUE) #> [1] 0.9238231"},{"path":"https://sevvandi.github.io/lookout/reference/lookout-package.html","id":null,"dir":"Reference","previous_headings":"","what":"lookout: Leave One Out Kernel Density Estimates for Outlier Detection — lookout-package","title":"lookout: Leave One Out Kernel Density Estimates for Outlier Detection — lookout-package","text":"Outlier detection using leave-one-kernel density estimates extreme value theory. bandwidth kernel density estimates computed using persistent homology, technique topological data analysis. Using peak--threshold method, generalized Pareto distribution fitted log leave-one-kde values identify outliers.","code":""},{"path":[]},{"path":"https://sevvandi.github.io/lookout/reference/lookout-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"lookout: Leave One Out Kernel Density Estimates for Outlier Detection — lookout-package","text":"Maintainer: Sevvandi Kandanaarachchi sevvandik@gmail.com (ORCID) Authors: Rob Hyndman rob.hyndman@monash.edu (ORCID) contributors: Chris Fraley fraley@u.washington.edu [contributor]","code":""},{"path":"https://sevvandi.github.io/lookout/reference/lookout.html","id":null,"dir":"Reference","previous_headings":"","what":"Identifies outliers using the algorithm lookout. — lookout","title":"Identifies outliers using the algorithm lookout. — lookout","text":"function identifies outliers using algorithm lookout, outlier detection method uses leave-one-kernel density estimates generalized Pareto distributions find outliers.","code":""},{"path":"https://sevvandi.github.io/lookout/reference/lookout.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identifies outliers using the algorithm lookout. — lookout","text":"","code":"lookout(   X,   alpha = 0.01,   beta = 0.9,   gamma = 0.97,   bw = NULL,   gpd = NULL,   scale = TRUE,   fast = NROW(X) > 1000,   old_version = FALSE )"},{"path":"https://sevvandi.github.io/lookout/reference/lookout.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identifies outliers using the algorithm lookout. — lookout","text":"X numerical input data data.frame, matrix tibble format. alpha level significance. Default 0.01. 1/100 chance point falsely classified outlier. beta quantile threshold used GPD estimation. Default 0.90. ensure enough data available, values greater 0.90 set 0.90. gamma Parameter bandwidth calculation giving quantile Rips death radii use bandwidth. Default 0.97. Ignored old version; lower limit maximum Rips death radii difference used. Also ignored bw provided. bw Bandwidth parameter. NULL (default), bandwidth found using Persistent Homology. gpd Generalized Pareto distribution parameters. NULL (default), estimated data. scale TRUE, data standardized. Using old version, unit scaling applied column range [0,1]. new version, robust rotation scaling used columns approximately uncorrelated unit variance. Default TRUE. fast TRUE (default), makes computation faster sub-setting data bandwidth calculation. old_version Logical indicator version algorithm use. Default FALSE, meaning newer version used.","code":""},{"path":"https://sevvandi.github.io/lookout/reference/lookout.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identifies outliers using the algorithm lookout. — lookout","text":"list following components: outliers set outliers. outlier_probability GPD probability data. outlier_scores outlier scores data. bandwidth bandwdith selected using persistent homology. kde kernel density estimate values. lookde leave-one-kde values. gpd fitted GPD parameters.","code":""},{"path":"https://sevvandi.github.io/lookout/reference/lookout.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identifies outliers using the algorithm lookout. — lookout","text":"","code":"X <- rbind(   data.frame(     x = rnorm(500),     y = rnorm(500)   ),   data.frame(     x = rnorm(5, mean = 10, sd = 0.2),     y = rnorm(5, mean = 10, sd = 0.2)   ) ) lo <- lookout(X) lo #> Leave-out-out KDE outliers using lookout algorithm #>  #> Call: lookout(X = X) #>  #>   Outliers  Probability #> 1      101 0.0019829565 #> 2      209 0.0004844054 #> 3      216 0.0047098869 #> 4      294 0.0000000000 #> 5      306 0.0001628749 #> 6      468 0.0002994101 #>  autoplot(lo)"},{"path":"https://sevvandi.github.io/lookout/reference/lookout_ts.html","id":null,"dir":"Reference","previous_headings":"","what":"Identifies outliers in univariate time series using the algorithm lookout. — lookout_ts","title":"Identifies outliers in univariate time series using the algorithm lookout. — lookout_ts","text":"time series implementation lookout identifies outliers double differenced time series.","code":""},{"path":"https://sevvandi.github.io/lookout/reference/lookout_ts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identifies outliers in univariate time series using the algorithm lookout. — lookout_ts","text":"","code":"lookout_ts(x, scale = FALSE, ...)"},{"path":"https://sevvandi.github.io/lookout/reference/lookout_ts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identifies outliers in univariate time series using the algorithm lookout. — lookout_ts","text":"x input univariate time series. scale TRUE, data standardized. Using old version, unit scaling applied column range [0,1]. new version, robust rotation scaling used columns approximately uncorrelated unit variance. Default TRUE. ... arguments passed lookout.","code":""},{"path":"https://sevvandi.github.io/lookout/reference/lookout_ts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identifies outliers in univariate time series using the algorithm lookout. — lookout_ts","text":"lookout object.","code":""},{"path":[]},{"path":"https://sevvandi.github.io/lookout/reference/lookout_ts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identifies outliers in univariate time series using the algorithm lookout. — lookout_ts","text":"","code":"set.seed(1) x <- arima.sim(list(order = c(1, 1, 0), ar = 0.8), n = 200) x[50] <- x[50] + 10 plot(x)  lo <- lookout_ts(x) lo #> Leave-out-out KDE outliers using lookout algorithm #>  #> Call: lookout(X = u, scale = scale) #>  #>   Outliers Probability #> 2       50           0 #>"},{"path":"https://sevvandi.github.io/lookout/reference/mvscale.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute robust multivariate scaled data — mvscale","title":"Compute robust multivariate scaled data — mvscale","text":"multivariate version base::scale(), takes account covariance matrix data, uses robust estimates center, scale covariance default. centers removed using medians, scale function IQR, covariance matrix estimated using robust OGK estimate. data scaled using Cholesky decomposition inverse covariance. scaled data returned. useful computing pairwise Mahalanobis distances.","code":""},{"path":"https://sevvandi.github.io/lookout/reference/mvscale.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute robust multivariate scaled data — mvscale","text":"","code":"mvscale(   object,   center = stats::median,   scale = robustbase::s_Qn,   cov = robustbase::covOGK,   warning = TRUE )"},{"path":"https://sevvandi.github.io/lookout/reference/mvscale.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute robust multivariate scaled data — mvscale","text":"object vector, matrix, data frame containing numerical data. center function compute center numerical variable. Set NULL centering required. scale function scale numerical variable. cov = robustbase::covOGK(), passed sigmamu argument. cov function compute covariance matrix. Set NULL rotation required. warning warning issued non-numeric columns ignored?","code":""},{"path":"https://sevvandi.github.io/lookout/reference/mvscale.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute robust multivariate scaled data — mvscale","text":"vector, matrix data frame size class object, numerical variables replaced scaled versions.","code":""},{"path":"https://sevvandi.github.io/lookout/reference/mvscale.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute robust multivariate scaled data — mvscale","text":"Optionally, centering scaling can done variable separately, rotation data, setting cov = NULL. Also optionally, non-robust methods can used specifying center = mean, scale = stats::sd(), cov = stats::cov(). non-numeric columns retained warning.","code":""},{"path":[]},{"path":"https://sevvandi.github.io/lookout/reference/mvscale.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Compute robust multivariate scaled data — mvscale","text":"Rob J Hyndman","code":""},{"path":"https://sevvandi.github.io/lookout/reference/mvscale.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute robust multivariate scaled data — mvscale","text":"","code":"# Univariate z-scores (no rotation) mvscale(faithful, center = mean, scale = sd, cov = NULL, warning = FALSE) #>       eruptions      waiting #> 1    0.09831763  0.596024774 #> 2   -1.47873278 -1.242890136 #> 3   -0.13561152  0.228241792 #> 4   -1.05555759 -0.654437365 #> 5    0.91575542  1.037364352 #> 6   -0.52987412 -1.169333540 #> 7    1.06207065  1.258034141 #> 8    0.09831763  1.037364352 #> 9   -1.34731192 -1.463559925 #> 10   0.75542196  1.037364352 #> 11  -1.44982019 -1.242890136 #> 12   0.37605373  0.963807756 #> 13   0.62400110  0.522468177 #> 14  -1.52253974 -1.757786311 #> 15   1.06207065  0.890251159 #> 16  -1.15718973 -1.390003329 #> 17  -1.52253974 -0.654437365 #> 18   1.14968457  0.963807756 #> 19  -1.65396061 -1.390003329 #> 20   0.66780805  0.596024774 #> 21  -1.47873278 -1.463559925 #> 22  -1.52253974 -1.757786311 #> 23  -0.03310324  0.522468177 #> 24  -0.36866452 -0.139541190 #> 25   0.91575542  0.228241792 #> 26   0.09831763  0.890251159 #> 27  -1.33241755 -1.169333540 #> 28   0.52149282  0.375354985 #> 29   0.31735241  0.522468177 #> 30   0.82814151  0.596024774 #> 31   0.71161501  0.154685195 #> 32   0.85793024  0.448911581 #> 33  -0.10582279 -0.360210979 #> 34   0.47768586  0.669581370 #> 35   0.30245804  0.228241792 #> 36  -1.28861060 -1.390003329 #> 37  -1.42003146 -1.684229714 #> 38   1.17859716  0.669581370 #> 39  -1.44982019 -0.875107154 #> 40   1.13479020  1.405147334 #> 41   0.75542196  0.669581370 #> 42  -1.40601324 -0.948663750 #> 43   0.94554415  0.963807756 #> 44  -1.52253974 -0.948663750 #> 45   0.91575542  0.154685195 #> 46  -0.14962974  0.890251159 #> 47   0.30245804 -0.507324172 #> 48  -1.21589105 -1.316446732 #> 49   1.00336933  0.816694563 #> 50  -1.30350496 -0.875107154 #> 51   1.14968457  0.301798388 #> 52   1.07608888  1.405147334 #> 53  -1.44982019 -1.242890136 #> 54   1.17859716  0.669581370 #> 55  -1.53743411 -1.242890136 #> 56   1.22240411  0.890251159 #> 57   0.20082590  0.007572003 #> 58  -1.59525929 -0.507324172 #> 59   0.94554415  0.448911581 #> 60   0.72650937  0.743137966 #> 61  -1.09936455 -0.875107154 #> 62   0.88684283  0.963807756 #> 63  -1.52253974 -1.684229714 #> 64   1.14968457  0.816694563 #> 65  -1.46383842 -0.801550558 #> 66   0.79922892  1.552260527 #> 67   0.59508851  0.522468177 #> 68   1.06207065  0.522468177 #> 69  -1.24480364 -0.433767576 #> 70   1.06207065  0.154685195 #> 71   0.47768586  0.816694563 #> 72  -1.33241755 -1.095776943 #> 73   0.88684283  0.596024774 #> 74   0.44877327  0.007572003 #> 75  -1.31839933 -0.654437365 #> 76   1.38361371  0.375354985 #> 77  -1.28861060 -0.801550558 #> 78   0.94554415  0.522468177 #> 79   0.34626500  0.375354985 #> 80   0.09831763  0.890251159 #> 81   0.56529978  0.301798388 #> 82   0.74052760  0.816694563 #> 83   0.53638718 -0.065984594 #> 84  -0.74890890 -0.433767576 #> 85   0.50747459  0.154685195 #> 86   1.26621107  1.258034141 #> 87   0.40496632  0.375354985 #> 88   0.90173720  0.669581370 #> 89  -1.15718973 -1.684229714 #> 90   0.44877327  1.110920948 #> 91  -1.12827714 -0.801550558 #> 92   0.74052760  1.405147334 #> 93  -1.42003146 -1.537116522 #> 94   1.16457893  0.522468177 #> 95  -1.44982019 -0.580880769 #> 96   0.71161501  0.081128599 #> 97   1.03315806  0.963807756 #> 98   0.22973849  0.301798388 #> 99  -1.42003146 -1.463559925 #> 100  1.23729848  0.816694563 #> 101 -0.88032977 -0.654437365 #> 102  0.77031633  1.258034141 #> 103 -1.21589105 -1.610673118 #> 104  0.88684283  0.890251159 #> 105  0.49258023  0.743137966 #> 106 -1.42003146 -1.757786311 #> 107  1.06207065  0.963807756 #> 108 -1.49362715 -1.390003329 #> 109  1.19349152  1.110920948 #> 110  0.17103717  0.743137966 #> 111  1.09098325  0.301798388 #> 112 -1.04066323 -0.875107154 #> 113  1.23729848  1.331590738 #> 114  0.81412328  0.596024774 #> 115 -1.56634670 -0.875107154 #> 116  1.00336933  0.743137966 #> 117 -1.02576886 -1.537116522 #> 118  0.97445674  1.037364352 #> 119 -1.46383842 -0.875107154 #> 120  0.81412328  1.184477545 #> 121 -0.76292713 -1.316446732 #> 122  0.50747459 -0.139541190 #> 123  0.66780805  0.448911581 #> 124 -1.33241755 -1.095776943 #> 125  0.97445674  1.258034141 #> 126  0.24463286  0.743137966 #> 127 -1.37622451 -1.904899504 #> 128  0.88684283  0.816694563 #> 129 -1.06957582 -1.169333540 #> 130  1.01826370  1.405147334 #> 131 -1.42003146 -1.904899504 #> 132  0.59508851  0.890251159 #> 133 -0.60259367 -1.095776943 #> 134  0.74052760  1.331590738 #> 135 -1.44982019 -1.831342907 #> 136  0.78433455  0.816694563 #> 137 -1.40601324 -1.463559925 #> 138  1.26621107  1.110920948 #> 139 -1.27459237 -1.316446732 #> 140  0.21484413  0.596024774 #> 141  0.65291369  0.743137966 #> 142 -1.09936455 -0.801550558 #> 143  0.91575542  0.816694563 #> 144  1.16457893  0.448911581 #> 145  0.74052760  0.375354985 #> 146 -1.31839933 -0.875107154 #> 147  1.00336933  0.669581370 #> 148 -1.28861060 -1.610673118 #> 149  1.41252630  1.846486912 #> 150 -1.47873278 -1.316446732 #> 151  1.35382498  0.448911581 #> 152  0.44877327  0.448911581 #> 153 -0.95304931 -0.433767576 #> 154  0.97445674  0.743137966 #> 155  0.06940504  0.007572003 #> 156  0.44877327 -0.065984594 #> 157  0.88684283  0.743137966 #> 158  0.52149282  1.625817123 #> 159 -1.47873278 -1.316446732 #> 160  0.41986068  1.331590738 #> 161 -1.12827714 -1.904899504 #> 162  0.58019414  1.110920948 #> 163 -1.30350496 -0.948663750 #> 164  0.30245804  0.522468177 #> 165  0.01070371 -0.360210979 #> 166  0.95956238  0.375354985 #> 167 -0.98196191 -0.580880769 #> 168  1.32491239  1.258034141 #> 169 -1.36220628 -1.390003329 #> 170  0.98935111  1.625817123 #> 171 -1.37622451 -1.610673118 #> 172 -1.23078541 -1.022220347 #> 173  0.95956238  0.448911581 #> 174 -0.13561152 -0.213097787 #> 175  0.59508851  0.743137966 #> 176  0.74052760  0.743137966 #> 177  0.88684283  0.154685195 #> 178 -0.93815495 -1.537116522 #> 179  0.44877327  1.037364352 #> 180  0.59508851  0.228241792 #> 181 -1.40601324 -1.169333540 #> 182  0.95956238  0.448911581 #> 183  0.66780805  0.890251159 #> 184  0.24463286  0.890251159 #> 185 -1.27459237 -1.463559925 #> 186  0.82814151  0.522468177 #> 187  0.52149282  0.963807756 #> 188 -1.44982019 -1.831342907 #> 189  0.81412328  0.890251159 #> 190 -1.14317150 -1.169333540 #> 191  1.14968457  0.743137966 #> 192 -1.44982019 -1.022220347 #> 193  1.14968457  0.375354985 #> 194  0.53638718  0.963807756 #> 195  0.41898454  0.448911581 #> 196  0.65291369  0.743137966 #> 197  0.01070371  1.184477545 #> 198  0.76944019  0.448911581 #> 199 -1.08447018 -1.463559925 #> 200  1.03315806  0.522468177 #> 201 -1.21589105 -0.801550558 #> 202  0.75542196  0.816694563 #> 203  0.56529978  1.478703930 #> 204 -1.42003146 -1.316446732 #> 205  0.97445674  0.522468177 #> 206 -1.49362715 -1.831342907 #> 207  0.77031633  0.448911581 #> 208  0.31735241  0.963807756 #> 209 -1.36220628 -1.610673118 #> 210  0.88684283  0.890251159 #> 211 -0.96794368  0.007572003 #> 212  1.06207065  0.669581370 #> 213 -1.42003146 -1.610673118 #> 214  0.30245804  0.301798388 #> 215 -0.06201583 -0.507324172 #> 216  0.65291369  0.375354985 #> 217 -0.95304931 -1.316446732 #> 218  1.14968457  1.699373720 #> 219 -1.30350496 -1.169333540 #> 220  0.58019414  0.375354985 #> 221 -1.42003146 -1.537116522 #> 222  0.68270242  0.816694563 #> 223 -1.52253974 -1.242890136 #> 224  0.87194847  0.301798388 #> 225  0.44877327  0.522468177 #> 226  0.55128155  0.596024774 #> 227  0.52149282  0.522468177 #> 228  0.68270242  0.522468177 #> 229  0.37605373 -0.065984594 #> 230  0.93064979  0.596024774 #> 231  0.52149282 -0.065984594 #> 232 -0.93815495 -1.242890136 #> 233  0.60910673  1.110920948 #> 234 -1.11338277 -1.537116522 #> 235  0.84303588  1.405147334 #> 236 -1.40601324 -1.242890136 #> 237 -1.43492583 -1.242890136 #> 238  0.69672064  0.448911581 #> 239  0.40496632  0.596024774 #> 240 -1.01175064 -0.507324172 #> 241  0.58019414  0.301798388 #> 242 -0.99685627 -1.757786311 #> 243  1.26621107  1.110920948 #> 244 -0.51497976 -0.580880769 #> 245  0.95956238  1.037364352 #> 246  0.30245804  0.816694563 #> 247 -1.23078541 -1.022220347 #> 248  0.77031633  0.816694563 #> 249 -1.18697846 -0.286654383 #> 250  0.75542196  0.228241792 #> 251 -1.12827714 -1.242890136 #> 252  0.84303588  0.890251159 #> 253  0.06940504  0.154685195 #> 254  0.88684283  0.154685195 #> 255  0.58019414  1.258034141 #> 256  0.28843981  0.669581370 #> 257  0.37605373  0.007572003 #> 258  0.84303588  0.890251159 #> 259 -1.30350496 -1.095776943 #> 260  0.69672064  0.596024774 #> 261  1.12077198  0.522468177 #> 262  0.91575542  0.963807756 #> 263 -1.43492583 -0.948663750 #> 264  0.66780805  0.890251159 #> 265 -1.31839933 -2.052012696 #> 266 -1.08447018 -0.801550558 #> 267  1.10587761  0.301798388 #> 268  0.55128155  0.743137966 #> 269 -1.17208409 -1.831342907 #> 270  0.81412328  1.405147334 #> 271 -1.46383842 -1.831342907 #> 272  0.85793024  0.228241792 # Non-robust scaling with rotation mvscale(faithful, center = mean, cov = stats::cov, warning = FALSE) #>              z1           z2 #> 1   -1.01008057  0.596024774 #> 2   -0.82707123 -1.242890136 #> 3   -0.78582586  0.228241792 #> 4   -1.07328706 -0.654437365 #> 5   -0.04309879  1.037364352 #> 6    1.20557638 -1.169333540 #> 7   -0.16393076  1.258034141 #> 8   -1.92568052  1.037364352 #> 9   -0.06660538 -1.463559925 #> 10  -0.41235116  1.037364352 #> 11  -0.76048474 -1.242890136 #> 12  -1.13344665  0.963807756 #> 13   0.35318292  0.522468177 #> 14   0.14024010 -1.757786311 #> 15   0.59906920  0.890251159 #> 16   0.21865126 -1.390003329 #> 17  -2.14875979 -0.654437365 #> 18   0.64824645  0.963807756 #> 19  -0.92542574 -1.390003329 #> 20   0.30147155  0.596024774 #> 21  -0.36927125 -1.463559925 #> 22   0.14024010 -1.757786311 #> 23  -1.16014645  0.522468177 #> 24  -0.55955338 -0.139541190 #> 25   1.63550113  0.228241792 #> 26  -1.62048054  0.890251159 #> 27  -0.64270321 -1.169333540 #> 28   0.42230352  0.375354985 #> 29  -0.35303745  0.522468177 #> 30   0.67072391  0.596024774 #> 31   1.31796013  0.154685195 #> 32   1.04452816  0.448911581 #> 33   0.50357835 -0.360210979 #> 34  -0.28898507  0.669581370 #> 35   0.22306039  0.228241792 #> 36  -0.08401461 -1.390003329 #> 37   0.22371948 -1.684229714 #> 38   1.32523292  0.669581370 #> 39  -1.52348470 -0.875107154 #> 40  -0.30165563  1.405147334 #> 41   0.35064881  0.669581370 #> 42  -1.26999608 -0.948663750 #> 43   0.17810547  0.963807756 #> 44  -1.53835982 -0.948663750 #> 45   1.78810112  0.154685195 #> 46  -2.19151015  0.890251159 #> 47   1.74906031 -0.507324172 #> 48  -0.06913949 -1.316446732 #> 49   0.61647843  0.816694563 #> 50  -1.18651669 -0.875107154 #> 51   2.02164639  0.301798388 #> 52  -0.43684639  1.405147334 #> 53  -0.76048474 -1.242890136 #> 54   1.32523292  0.669581370 #> 55  -0.96226198 -1.242890136 #> 56   0.96832156  0.890251159 #> 57   0.44679876  0.007572003 #> 58  -2.62143489 -0.507324172 #> 59   1.24630541  0.448911581 #> 60   0.13146232  0.743137966 #> 61  -0.71637570 -0.875107154 #> 62   0.04291471  0.963807756 #> 63  -0.01235990 -1.684229714 #> 64   0.95344644  0.816694563 #> 65  -1.70836905 -0.801550558 #> 66  -1.37966248  1.552260527 #> 67   0.28659643  0.522468177 #> 68   1.36206916  0.522468177 #> 69  -1.96692589 -0.433767576 #> 70   2.12506912  0.154685195 #> 71  -0.59418506  0.816694563 #> 72  -0.79530321 -1.095776943 #> 73   0.80591467  0.596024774 #> 74   1.01782837  0.007572003 #> 75  -1.67861880 -0.654437365 #> 76   2.40779165  0.375354985 #> 77  -1.30481455 -0.801550558 #> 78   1.09370542  0.522468177 #> 79   0.01874903  0.375354985 #> 80  -1.62048054  0.890251159 #> 81   0.67579214  0.301798388 #> 82   0.01114669  0.816694563 #> 83   1.37220561 -0.065984594 #> 84  -0.82486666 -0.433767576 #> 85   0.84781914  0.154685195 #> 86   0.30621022  1.258034141 #> 87   0.15393978  0.375354985 #> 88   0.68761681  0.669581370 #> 89   0.82905123 -1.684229714 #> 90  -1.27117152  1.110920948 #> 91  -0.93556219 -0.801550558 #> 92  -1.20965325  1.405147334 #> 93  -0.08148050 -1.537116522 #> 94   1.59814854  0.522468177 #> 95  -2.13388467 -0.580880769 #> 96   1.47056012  0.081128599 #> 97   0.37988271  0.963807756 #> 98  -0.09701472  0.301798388 #> 99  -0.23408049 -1.463559925 #> 100  1.15522369  0.816694563 #> 101 -0.66973256 -0.654437365 #> 102 -0.83584900  1.258034141 #> 103  0.54126048 -1.610673118 #> 104  0.19551470  0.890251159 #> 105 -0.40728293  0.743137966 #> 106  0.37631948 -1.757786311 #> 107  0.44646921  0.963807756 #> 108 -0.55617337 -1.390003329 #> 109  0.44393509  1.110920948 #> 110 -1.14780543  0.743137966 #> 111  1.88645563  0.301798388 #> 112 -0.58118495 -0.875107154 #> 113  0.08702374  1.331590738 #> 114  0.63843955  0.596024774 #> 115 -1.79184844 -0.875107154 #> 116  0.76907843  0.743137966 #> 117  0.82651712 -1.537116522 #> 118  0.09209196  1.037364352 #> 119 -1.55576906 -0.875107154 #> 120 -0.58236039  1.184477545 #> 121  0.97404889 -1.316446732 #> 122  1.45821911 -0.139541190 #> 123  0.60667153  0.448911581 #> 124 -0.79530321 -1.095776943 #> 125 -0.36570801  1.258034141 #> 126 -0.97831255  0.743137966 #> 127  0.78240809 -1.904899504 #> 128  0.34811469  0.816694563 #> 129 -0.03737147 -1.169333540 #> 130 -0.57001937  1.405147334 #> 131  0.68151946 -1.904899504 #> 132 -0.47640354  0.890251159 #> 133  0.88550127 -1.095776943 #> 134 -1.05705326  1.331590738 #> 135  0.46031521 -1.831342907 #> 136  0.11203531  0.816694563 #> 137 -0.20179613 -1.463559925 #> 138  0.61141021  1.110920948 #> 139 -0.20433025 -1.316446732 #> 140 -0.74171683  0.596024774 #> 141 -0.03803057  0.743137966 #> 142 -0.86897570 -0.801550558 #> 143  0.41470119  0.816694563 #> 144  1.75074853  0.448911581 #> 145  0.92674664  0.375354985 #> 146 -1.22081882 -0.875107154 #> 147  0.92167842  0.669581370 #> 148  0.37378536 -1.610673118 #> 149 -0.57762171  1.846486912 #> 150 -0.67447123 -1.316446732 #> 151  2.18658739  0.448911581 #> 152  0.10222841  0.448911581 #> 153 -1.29500765 -0.433767576 #> 154  0.70249193  0.743137966 #> 155  0.14413288  0.007572003 #> 156  1.17042836 -0.065984594 #> 157  0.50071469  0.743137966 #> 158 -2.17189635  1.625817123 #> 159 -0.67447123 -1.316446732 #> 160 -1.79555799  1.331590738 #> 161  1.35343770 -1.904899504 #> 162 -0.96850565  1.110920948 #> 163 -1.03391670 -0.948663750 #> 164 -0.38733958  0.522468177 #> 165  0.77194209 -0.360210979 #> 166  1.43118977  0.375354985 #> 167 -1.05639416 -0.580880769 #> 168  0.44140098  1.258034141 #> 169 -0.25350750 -1.390003329 #> 170 -1.09440584  1.625817123 #> 171  0.17200812 -1.610673118 #> 172 -0.71384159 -1.022220347 #> 173  1.27858977  0.448911581 #> 174  0.12977410 -0.213097787 #> 175 -0.17120355  0.743137966 #> 176  0.16374668  0.743137966 #> 177  1.72151463  0.154685195 #> 178  1.02829437 -1.537116522 #> 179 -1.11857153  1.037364352 #> 180  0.89699640  0.228241792 #> 181 -0.81219610 -1.169333540 #> 182  1.27858977  0.448911581 #> 183 -0.30892842  0.890251159 #> 184 -1.28351253  0.890251159 #> 185  0.10086974 -1.463559925 #> 186  0.82332391  0.522468177 #> 187 -0.79849642  0.963807756 #> 188  0.46031521 -1.831342907 #> 189  0.02803958  0.890251159 #> 190 -0.20686436 -1.169333540 #> 191  1.10604643  0.743137966 #> 192 -1.21828471 -1.022220347 #> 193  1.86904639  0.375354985 #> 194 -0.76419429  0.963807756 #> 195  0.03362415  0.448911581 #> 196 -0.03803057  0.743137966 #> 197 -2.43265775  1.184477545 #> 198  0.84073314  0.448911581 #> 199  0.53872637 -1.463559925 #> 200  1.29548267  0.522468177 #> 201 -1.13733944 -0.801550558 #> 202  0.04544882  0.816694563 #> 203 -1.76580774  1.478703930 #> 204 -0.53928048 -1.316446732 #> 205  1.16029191  0.522468177 #> 206  0.35942658 -1.831342907 #> 207  0.84275092  0.448911581 #> 208 -1.26863741  0.963807756 #> 209  0.20429248 -1.610673118 #> 210  0.19551470  0.890251159 #> 211 -2.24490974  0.007572003 #> 212  1.05686918  0.669581370 #> 213  0.07111949 -1.610673118 #> 214  0.07046039  0.301798388 #> 215  0.90966696 -0.507324172 #> 216  0.72496940  0.375354985 #> 217  0.53619226 -1.316446732 #> 218 -0.87775347  1.699373720 #> 219 -0.57611672 -1.169333540 #> 220  0.55749428  0.375354985 #> 221 -0.08148050 -1.537116522 #> 222 -0.12202630  0.816694563 #> 223 -0.92795985 -1.242890136 #> 224  1.38201251  0.301798388 #> 225 -0.05037158  0.522468177 #> 226  0.03310781  0.596024774 #> 227  0.11710354  0.522468177 #> 228  0.48837367  0.522468177 #> 229  1.00295324 -0.065984594 #> 230  0.90680330  0.596024774 #> 231  1.33790348 -0.065984594 #> 232  0.41789440 -1.242890136 #> 233 -0.90191915  1.110920948 #> 234  0.62473987 -1.537116522 #> 235 -0.97357387  1.405147334 #> 236 -0.65959611 -1.242890136 #> 237 -0.72618260 -1.242890136 #> 238  0.67325803  0.448911581 #> 239 -0.30386020  0.596024774 #> 240 -1.27759842 -0.507324172 #> 241  0.71009427  0.301798388 #> 242  1.35090359 -1.757786311 #> 243  0.61141021  1.110920948 #> 244  0.01907857 -0.580880769 #> 245  0.05778983  1.037364352 #> 246 -0.99773955  0.816694563 #> 247 -0.71384159 -1.022220347 #> 248  0.07975095  0.816694563 #> 249 -2.13895289 -0.286654383 #> 250  1.26624876  0.228241792 #> 251 -0.01996223 -1.242890136 #> 252  0.09462608  0.890251159 #> 253 -0.16106710  0.154685195 #> 254  1.72151463  0.154685195 #> 255 -1.27370563  1.258034141 #> 256 -0.72482393  0.669581370 #> 257  0.85035325  0.007572003 #> 258  0.09462608  0.890251159 #> 259 -0.72871672 -1.095776943 #> 260  0.36805804  0.596024774 #> 261  1.49725992  0.522468177 #> 262  0.10950120  0.963807756 #> 263 -1.33658257 -0.948663750 #> 264 -0.30892842  0.890251159 #> 265  1.22078106 -2.052012696 #> 266 -0.83467356 -0.801550558 #> 267  1.92075776  0.301798388 #> 268 -0.27209218  0.743137966 #> 269  1.09994908 -1.831342907 #> 270 -1.04016036  1.405147334 #> 271  0.42803085 -1.831342907 #> 272  1.50232814  0.228241792 # Robust scaling mvscale(faithful, warning = FALSE) #>                z1          z2 #> 1   -0.8926101362  0.27987381 #> 2   -1.9396028817 -2.05240797 #> 3   -0.9482794942 -0.18658254 #> 4   -1.7582943942 -1.30607780 #> 5    0.1868221521  0.83962144 #> 6   -0.2265380947 -1.95911670 #> 7    0.2314641809  1.11949526 #> 8   -1.3554287648  0.83962144 #> 9   -1.4602432592 -2.33228179 #> 10  -0.1156772239  0.83962144 #> 11  -1.8850538139 -2.05240797 #> 12  -0.7542906754  0.74633017 #> 13   0.1763275347  0.18658254 #> 14  -1.4822979177 -2.70544687 #> 15   0.6171463715  0.65303890 #> 16  -1.1786782515 -2.23899052 #> 17  -2.6393444893 -1.30607780 #> 18   0.7053101388  0.74633017 #> 19  -2.1159304164 -2.23899052 #> 20   0.1818411993  0.27987381 #> 21  -1.7081935674 -2.33228179 #> 22  -1.4822979177 -2.70544687 #> 23  -1.0634240062  0.18658254 #> 24  -1.0022958502 -0.65303890 #> 25   1.0353229713 -0.18658254 #> 26  -1.2011558886  0.65303890 #> 27  -1.7406879767 -1.95911670 #> 28   0.1371991705  0.00000000 #> 29  -0.4022231844  0.18658254 #> 30   0.4843405753  0.27987381 #> 31   0.7273099307 -0.27987381 #> 32   0.6948155214  0.09329127 #> 33  -0.2749859195 -0.93291271 #> 34  -0.2539966846  0.37316509 #> 35  -0.1217784669 -0.18658254 #> 36  -1.4266285597 -2.23899052 #> 37  -1.3660331154 -2.61215560 #> 38   1.0684049590  0.37316509 #> 39  -2.2707360045 -1.58595161 #> 40   0.2143904752  1.30607780 #> 41   0.2700049667  0.37316509 #> 42  -2.1109494636 -1.67924289 #> 43   0.3201606601  0.74633017 #> 44  -2.3307987369 -1.67924289 #> 45   1.1124594094 -0.27987381 #> 46  -1.6689554700  0.65303890 #> 47   0.6495859142 -1.11949526 #> 48  -1.3665658273 -2.14569924 #> 49   0.5835316719  0.55974763 #> 50  -1.9946846614 -1.58595161 #> 51   1.3995380818 -0.09329127 #> 52   0.1036393376  1.30607780 #> 53  -1.8850538139 -2.05240797 #> 54   1.0684049590  0.37316509 #> 55  -2.0503540194 -2.05240797 #> 56   0.9196457475  0.65303890 #> 57  -0.0821173909 -0.46645636 #> 58  -2.9308165361 -1.11949526 #> 59   0.8601157268  0.09329127 #> 60   0.1383194608  0.46645636 #> 61  -1.6095351826 -1.58595161 #> 62   0.2094095224  0.74633017 #> 63  -1.5594343558 -2.61215560 #> 64   0.8595830150  0.55974763 #> 65  -2.3743204755 -1.49266034 #> 66  -0.5729821879  1.49266034 #> 67   0.1217784669  0.18658254 #> 68   1.0028285620  0.18658254 #> 69  -2.3467521523 -1.02620399 #> 70   1.3885107525 -0.27987381 #> 71  -0.4082695608  0.55974763 #> 72  -1.8178244148 -1.86582543 #> 73   0.5950917130  0.27987381 #> 74   0.3856821905 -0.46645636 #> 75  -2.2541950106 -1.30607780 #> 76   1.7637531923  0.00000000 #> 77  -2.0437200645 -1.49266034 #> 78   0.7829792887  0.18658254 #> 79  -0.1934012404  0.00000000 #> 80  -1.2011558886  0.65303890 #> 81   0.2969857114 -0.09329127 #> 82   0.0876310555  0.55974763 #> 83   0.6281188341 -0.55974763 #> 84  -1.4111529894 -1.02620399 #> 85   0.3421604520 -0.27987381 #> 86   0.6166136596  1.11949526 #> 87  -0.0826501027  0.00000000 #> 88   0.5460563098  0.37316509 #> 89  -0.8701324991 -2.61215560 #> 90  -0.7713643811  0.93291271 #> 91  -1.7412206885 -1.49266034 #> 92  -0.5294604493  1.30607780 #> 93  -1.5203059916 -2.42557306 #> 94   1.1962298024  0.18658254 #> 95  -2.5792817569 -1.21278653 #> 96   0.8044463688 -0.37316509 #> 97   0.4854608656  0.74633017 #> 98  -0.3361140755 -0.09329127 #> 99  -1.5974424298 -2.33228179 #> 100  1.0248832205  0.55974763 #> 101 -1.4276939833 -1.30607780 #> 102 -0.3189855033  1.11949526 #> 103 -1.0580200748 -2.51886433 #> 104  0.2865459605  0.65303890 #> 105 -0.3030320878  0.46645636 #> 106 -1.2888966773 -2.70544687 #> 107  0.5400099334  0.74633017 #> 108 -1.8134310404 -2.23899052 #> 109  0.6336873653  0.93291271 #> 110 -0.9096838418  0.46645636 #> 111  1.2887869441 -0.09329127 #> 112 -1.4987840450 -1.58595161 #> 113  0.4849281537  1.21278653 #> 114  0.4578925424  0.27987381 #> 115 -2.4905852777 -1.58595161 #> 116  0.6606681100  0.46645636 #> 117 -0.7764550671 -2.42557306 #> 118  0.2975732898  0.83962144 #> 119 -2.2971840373 -1.58595161 #> 120 -0.1591989624  1.02620399 #> 121 -0.5119637650 -2.14569924 #> 122  0.6507062044 -0.65303890 #> 123  0.3361140755  0.09329127 #> 124 -1.8178244148 -1.86582543 #> 125  0.0661639755  1.11949526 #> 126 -0.7708316693  0.46645636 #> 127 -1.0519736984 -2.89202942 #> 128  0.3636823987  0.55974763 #> 129 -1.2447873603 -1.95911670 #> 130 -0.0054587980  1.30607780 #> 131 -1.1346238011 -2.89202942 #> 132 -0.2639037236  0.65303890 #> 133 -0.4408737034 -1.86582543 #> 134 -0.4523240112  1.21278653 #> 135 -1.2679623091 -2.79873814 #> 136  0.1702811583  0.55974763 #> 137 -1.5709943969 -2.33228179 #> 138  0.7708865359  0.93291271 #> 139 -1.4773169649 -2.14569924 #> 140 -0.6727608629  0.27987381 #> 141 -0.0005327118  0.46645636 #> 142 -1.6866716207 -1.49266034 #> 143  0.4182314665  0.55974763 #> 144  1.2733662405  0.09329127 #> 145  0.5504496842  0.00000000 #> 146 -2.0227856963 -1.58595161 #> 147  0.7378045481  0.37316509 #> 148 -1.1952192454 -2.51886433 #> 149  0.2755734979  1.86582543 #> 150 -1.8624664436 -2.14569924 #> 151  1.6304146843  0.09329127 #> 152 -0.0771364381  0.09329127 #> 153 -1.7963024682 -1.02620399 #> 154  0.6061190422  0.46645636 #> 155 -0.3300676991 -0.46645636 #> 156  0.4628186286 -0.55974763 #> 157  0.4408188368  0.46645636 #> 158 -1.1741202773  1.58595161 #> 159 -1.8624664436 -2.14569924 #> 160 -1.0573227632  1.21278653 #> 161 -0.5841741169 -2.89202942 #> 162 -0.5234140729  0.93291271 #> 163 -1.9175482233 -1.67924289 #> 164 -0.4303242193  0.18658254 #> 165 -0.0551366462 -0.93291271 #> 166  0.9637001978  0.00000000 #> 167 -1.6965786598 -1.21278653 #> 168  0.7273647973  1.11949526 #> 169 -1.5654807323 -2.23899052 #> 170 -0.2914171801  1.58595161 #> 171 -1.3605194508 -2.51886433 #> 172 -1.7032126146 -1.77253416 #> 173  0.8865637597  0.09329127 #> 174 -0.4854608656 -0.74633017 #> 175 -0.1096308474  0.46645636 #> 176  0.1647674936  0.46645636 #> 177  1.0579103416 -0.27987381 #> 178 -0.6111548616 -2.42557306 #> 179 -0.6942279430  0.83962144 #> 180  0.4303242193 -0.18658254 #> 181 -1.8795401493 -1.95911670 #> 182  0.8865637597  0.09329127 #> 183 -0.1267045531  0.65303890 #> 184 -0.9251045455  0.65303890 #> 185 -1.3230440887 -2.33228179 #> 186  0.5614770134  0.18658254 #> 187 -0.4798923343  0.74633017 #> 188 -1.2679623091 -2.79873814 #> 189  0.1493467900  0.65303890 #> 190 -1.3836395329 -1.95911670 #> 191  0.9367194531  0.46645636 #> 192 -2.1164631283 -1.77253416 #> 193  1.3224016437  0.00000000 #> 194 -0.4517912994  0.74633017 #> 195 -0.1333385080  0.09329127 #> 196 -0.0005327118  0.46645636 #> 197 -1.6750018465  1.02620399 #> 198  0.5278623139  0.09329127 #> 199 -0.9643426428 -2.33228179 #> 200  0.9482794942  0.18658254 #> 201 -1.9065208940 -1.49266034 #> 202  0.1157320905  0.55974763 #> 203 -0.9371972984  1.39936907 #> 204 -1.7517153060 -2.14569924 #> 205  0.8375283565  0.18658254 #> 206 -1.3506124118 -2.79873814 #> 207  0.5295153159  0.09329127 #> 208 -0.8650418131  0.74633017 #> 209 -1.3340714179 -2.51886433 #> 210  0.2865459605  0.65303890 #> 211 -2.2872221317 -0.46645636 #> 212  0.8485556858  0.37316509 #> 213 -1.4431695535 -2.51886433 #> 214 -0.1989149050 -0.09329127 #> 215 -0.0380629405 -1.11949526 #> 216  0.3851494787  0.00000000 #> 217 -0.8706652109 -2.14569924 #> 218 -0.0660542423  1.67924289 #> 219 -1.6861389089 -1.95911670 #> 220  0.2479503082  0.00000000 #> 221 -1.5203059916 -2.42557306 #> 222 -0.0214670801  0.55974763 #> 223 -2.0222529845 -2.05240797 #> 224  0.8755364305 -0.09329127 #> 225 -0.1542728762  0.18658254 #> 226 -0.0380080739  0.27987381 #> 227 -0.0170737057  0.18658254 #> 228  0.2870786724  0.18658254 #> 229  0.3256194581 -0.55974763 #> 230  0.6777418157  0.27987381 #> 231  0.6000177992 -0.55974763 #> 232 -0.9197006141 -2.05240797 #> 233 -0.4688650051  0.93291271 #> 234 -0.9417552725 -2.42557306 #> 235 -0.3360592089  1.30607780 #> 236 -1.8024037112 -2.05240797 #> 237 -1.8569527790 -2.05240797 #> 238  0.3906631433  0.09329127 #> 239 -0.3140594171  0.27987381 #> 240 -1.8299171677 -1.11949526 #> 241  0.3250867463 -0.09329127 #> 242 -0.4904966850 -2.70544687 #> 243  0.7708865359  0.93291271 #> 244 -0.8155285647 -1.21278653 #> 245  0.2694722549  0.83962144 #> 246 -0.7388699718  0.55974763 #> 247 -1.7032126146 -1.77253416 #> 248  0.1438331254  0.55974763 #> 249 -2.3919268930 -0.83962144 #> 250  0.7328235953 -0.18658254 #> 251 -1.2784020599 -2.05240797 #> 252  0.2038958578  0.65303890 #> 253 -0.4843405753 -0.27987381 #> 254  1.0579103416 -0.27987381 #> 255 -0.6776869491  1.11949526 #> 256 -0.6110451284  0.37316509 #> 257  0.2484830200 -0.46645636 #> 258  0.2038958578  0.65303890 #> 259 -1.7632753470 -1.86582543 #> 260  0.2363902671  0.27987381 #> 261  1.1135796997  0.18658254 #> 262  0.2639585902  0.74633017 #> 263 -2.1654985314 -1.67924289 #> 264 -0.1267045531  0.65303890 #> 265 -0.7886026866 -3.07861196 #> 266 -1.6585705858 -1.49266034 #> 267  1.3168879791 -0.09329127 #> 268 -0.1922809502  0.46645636 #> 269 -0.7439606578 -2.79873814 #> 270 -0.3906082767  1.30607780 #> 271 -1.2944103419 -2.79873814 #> 272  0.9262248357 -0.18658254"},{"path":"https://sevvandi.github.io/lookout/reference/persisting_outliers.html","id":null,"dir":"Reference","previous_headings":"","what":"Computes outlier persistence for a range of significance values. — persisting_outliers","title":"Computes outlier persistence for a range of significance values. — persisting_outliers","text":"function computes outlier persistence range significance values, using algorithm lookout, outlier detection method uses leave-one-kernel density estimates generalized Pareto distributions find outliers.","code":""},{"path":"https://sevvandi.github.io/lookout/reference/persisting_outliers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Computes outlier persistence for a range of significance values. — persisting_outliers","text":"","code":"persisting_outliers(   X,   alpha = seq(0.01, 0.1, by = 0.01),   st_qq = 0.9,   scale = TRUE,   num_steps = 20,   old_version = FALSE )"},{"path":"https://sevvandi.github.io/lookout/reference/persisting_outliers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Computes outlier persistence for a range of significance values. — persisting_outliers","text":"X input data matrix, data.frame, tibble format. columns numeric. alpha Grid significance levels. st_qq starting quantile death radii sequence. used compute starting bandwidth value. scale TRUE, data scaled. Default TRUE. scaling method used depends old_version parameter. See lookout details. num_steps length bandwidth sequence. old_version Logical indicator version algorithm use.","code":""},{"path":"https://sevvandi.github.io/lookout/reference/persisting_outliers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Computes outlier persistence for a range of significance values. — persisting_outliers","text":"list following components: 3D array N x num_steps x num_alpha N denotes number observations, num_steps denote length bandwidth sequence, num_alpha denotes number significance levels. binary array entries set 1 observation outlier particular bandwidth significance level. bw set bandwidth values. gpdparas GPD parameters used. lookoutbw bandwidth chosen algorithm lookout using persistent homology.","code":""},{"path":"https://sevvandi.github.io/lookout/reference/persisting_outliers.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Computes outlier persistence for a range of significance values. — persisting_outliers","text":"","code":"X <- rbind(   data.frame(     x = rnorm(500),     y = rnorm(500)   ),   data.frame(     x = rnorm(5, mean = 10, sd = 0.2),     y = rnorm(5, mean = 10, sd = 0.2)   ) ) plot(X, pch = 19)  outliers <- persisting_outliers(X, scale = FALSE) outliers #> Persistent outliers using lookout algorithm #>  #> Call: persisting_outliers(X = X, scale = FALSE) #>  #> Lookout bandwidth:  3.049485  autoplot(outliers)"},{"path":"https://sevvandi.github.io/lookout/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. ggplot2 autoplot","code":""}]
